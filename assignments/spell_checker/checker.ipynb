{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is here\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('Cuda is here')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(torch.cuda.is_available())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def book_loader(path):\n",
    "    \"\"\"Load a book from its file\"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file) as f:\n",
    "        book = f.read()\n",
    "    return book"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 books: \n",
      "Alices_Adventures_in_Wonderland_by_Lewis_Carroll.rtf\n",
      "Anna_Karenina_by_Leo_Tolstoy.rtf\n",
      "David_Copperfield_by_Charles_Dickens.rtf\n",
      "Don_Quixote_by_Miguel_de_Cervantes.rtf\n",
      "Dracula_by_Bram_Stoker.rtf\n",
      "Emma_by_Jane_Austen.rtf\n",
      "Frankenstein_by_Mary_Shelley.rtf\n",
      "Great_Expectations_by_Charles_Dickens.rtf\n",
      "Grimms_Fairy_Tales_by_The_Brothers_Grimm.rtf\n",
      "Metamorphosis_by_Franz_Kafka.rtf\n",
      "Oliver_Twist_by_Charles_Dickens.rtf\n",
      "Pride_and_Prejudice_by_Jane_Austen.rtf\n",
      "The_Adventures_of_Sherlock_Holmes_by_Arthur_Conan_Doyle.rtf\n",
      "The_Adventures_of_Tom_Sawyer_by_Mark_Twain.rtf\n",
      "The_Count_of_Monte_Cristo_by_Alexandre_Dumas.rtf\n",
      "The_Picture_of_Dorian_Gray_by_Oscar_Wilde.rtf\n",
      "The_Prince_by_Nicolo_Machiavelli.rtf\n",
      "The_Romance_of_Lust_by_Anonymous.rtf\n",
      "The_Yellow_Wallpaper_by_Charlotte_Perkins_Gilman.rtf\n",
      "Through_the_Looking_Glass_by_Lewis_Carroll.rtf\n"
     ]
    }
   ],
   "source": [
    "path = './books/'\n",
    "book_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "print('There are {} books: '.format(len(book_files)))\n",
    "for elem in book_files:\n",
    "    print(elem)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "books = []\n",
    "for book in book_files:\n",
    "    books.append(book_loader(path+book))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9463 words in The_Yellow_Wallpaper_by_Charlotte_Perkins_Gilman.rtf.\n",
      "There are 25395 words in Metamorphosis_by_Franz_Kafka.rtf.\n",
      "There are 30423 words in Alices_Adventures_in_Wonderland_by_Lewis_Carroll.rtf.\n",
      "There are 33464 words in Through_the_Looking_Glass_by_Lewis_Carroll.rtf.\n",
      "There are 53211 words in The_Prince_by_Nicolo_Machiavelli.rtf.\n",
      "There are 78912 words in Frankenstein_by_Mary_Shelley.rtf.\n",
      "There are 83657 words in The_Picture_of_Dorian_Gray_by_Oscar_Wilde.rtf.\n",
      "There are 96185 words in The_Adventures_of_Tom_Sawyer_by_Mark_Twain.rtf.\n",
      "There are 105428 words in Grimms_Fairy_Tales_by_The_Brothers_Grimm.rtf.\n",
      "There are 110213 words in The_Adventures_of_Sherlock_Holmes_by_Arthur_Conan_Doyle.rtf.\n",
      "There are 113452 words in David_Copperfield_by_Charles_Dickens.rtf.\n",
      "There are 126999 words in Pride_and_Prejudice_by_Jane_Austen.rtf.\n",
      "There are 163109 words in Emma_by_Jane_Austen.rtf.\n",
      "There are 165188 words in Oliver_Twist_by_Charles_Dickens.rtf.\n",
      "There are 166996 words in Dracula_by_Bram_Stoker.rtf.\n",
      "There are 191598 words in Great_Expectations_by_Charles_Dickens.rtf.\n",
      "There are 194282 words in The_Romance_of_Lust_by_Anonymous.rtf.\n",
      "There are 361612 words in Anna_Karenina_by_Leo_Tolstoy.rtf.\n",
      "There are 433993 words in Don_Quixote_by_Miguel_de_Cervantes.rtf.\n",
      "There are 480495 words in The_Count_of_Monte_Cristo_by_Alexandre_Dumas.rtf.\n"
     ]
    }
   ],
   "source": [
    "lens = [(len(books[i].split()), book_files[i]) for i in range(len(books))]\n",
    "lens.sort()\n",
    "for elem in lens:\n",
    "    print(\"There are {} words in {}.\".format(elem[0], elem[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's check for text existence."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "\"{\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf1404\\\\cocoasubrtf470\\n{\\\\fonttbl\\\\f0\\\\fmodern\\\\fcharset0 Courier;}\\n{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;\\\\red0\\\\green0\\\\blue0;}\\n\\\\margl1440\\\\margr1440\\\\vieww10800\\\\viewh8400\\\\viewkind0\\n\\\\deftab720\\n\\\\pard\\\\pardeftab720\\\\sl280\\\\partightenfactor0\\n\\n\\\\f0\\\\fs24 \\\\cf2 \\\\expnd0\\\\expndtw0\\\\kerning0\\n\\\\outl0\\\\strokewidth0 \\\\strokec2 Project Gutenberg\\\\'92s Alice\\\\'92s Adventures in Wonderland, by Lewis Carroll\\\\\\n\\\\\\nThis eBook is for the use of anyone anywhere at no cost and with\\\\\\nalmost no restrictions what\""
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[0][:500]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### There are a lot of trash in *.rtf."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Remove unwanted characters and extra spaces from the text'''\n",
    "    text = text[326:-1] # Header removing.\n",
    "    # text = re.sub('www.gutenberg.(net|org)', '.', text)\n",
    "    # text = re.sub(' www.gutenberg.org', '.', text)\n",
    "    text = re.sub('www.gutenberg.(net|org)(\\/license)*(\\.)*', 'our website.', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'[{}@_*>()\\\\#%+=\\[\\]]', '', text)\n",
    "    text = re.sub('a0', '', text)\n",
    "    text = re.sub('\\'92t', '\\'t', text)\n",
    "    text = re.sub('\\'92s', '\\'s', text)\n",
    "    text = re.sub('\\'92m', '\\'m', text)\n",
    "    text = re.sub('\\'92ll', '\\'ll', text)\n",
    "    text = re.sub('\\'91', '', text)\n",
    "    text = re.sub('\\'92', '', text)\n",
    "    text = re.sub('\\'93', '', text)\n",
    "    text = re.sub('\\'94', '', text)\n",
    "    text = re.sub('\\.', '. ', text)\n",
    "    text = re.sub('\\!', '! ', text)\n",
    "    text = re.sub('\\?', '? ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('\"', ' ', text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "clean_books = []\n",
    "for book in books:\n",
    "    clean_books.append(clean_text(book))\n",
    "# clean_books.append(clean_text(books[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's check."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "' The Project Gutenberg EBook of Don Quixote, by Miguel de Cervantes This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at our website. Title: Don Quixote Author: Miguel de Cervantes Saavedra Release Date: July 27, 2004 EBook 996 Last Updated: March 4,2015 Language: English START OF THIS PROJECT GUTENBERG EBOOK DON QUIXOTE '"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_books[3][:500]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We'll need a dictionary to convert character <---> integers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "vocab_to_int = {}\n",
    "count = 0\n",
    "for book in clean_books:\n",
    "    for character in book:\n",
    "        if character not in vocab_to_int:\n",
    "            vocab_to_int[character] = count\n",
    "            count += 1\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<SOS>']\n",
    "for token in tokens:\n",
    "    vocab_to_int[token] = count\n",
    "    count += 1\n",
    "\n",
    "int_to_vocab = {}\n",
    "for character, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = character"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 77 characters.\n",
      "[' ', '!', '$', '&', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<EOS>', '<PAD>', '<SOS>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)\n",
    "print(\"The vocabulary contains {} characters.\".format(vocab_size))\n",
    "print(sorted(vocab_to_int))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now let's split text into sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 161985 sentences.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "splited = []\n",
    "\n",
    "for book in clean_books:\n",
    "    raw_splited = book.split('. ')\n",
    "    for sent in raw_splited:\n",
    "        for first_splited in sent.split('! '):\n",
    "            for second_splited in first_splited.split('? '):\n",
    "                splited.append(second_splited+'.')   # So, model won't know about '!' and '?'. Bad..\n",
    "\n",
    "# for book in clean_books:\n",
    "#     for sentence in book.split('. '):\n",
    "#     # for sentence in re.split('. |! |\\? ', book):\n",
    "#         sentences.append(sentence + '.')\n",
    "sentences = splited\n",
    "print(\"There are {} sentences.\".format(len(sentences)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "['In another moment down went Alice after it, never once considering how in the world she was to get out again.',\n 'The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that Alice had not a moment to think about stopping herself before she found herself falling down a very deep well.',\n 'Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next.',\n 'First, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.',\n 'She took down a jar from one of the shelves as she passed; it was labelled ORANGE MARMALADE, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.']"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[10:15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "int_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    int_sentence = [vocab_to_int[character] for character in sentence]\n",
    "    int_sentences.append(int_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "# int_sentences[10:15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for sentence in int_sentences:\n",
    "    lengths.append(len(sentence))\n",
    "lengths = pd.DataFrame(lengths, columns=[\"counts\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "              counts\ncount  161985.000000\nmean       99.069222\nstd       103.371173\nmin         1.000000\n25%        31.000000\n50%        70.000000\n75%       135.000000\nmax      8906.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>161985.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>99.069222</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>103.371173</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>70.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>135.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8906.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 90733 sentences. \n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "min_length = 10\n",
    "\n",
    "good_sentences = []\n",
    "\n",
    "for sentence in int_sentences:\n",
    "    if max_length >= len(sentence) >= min_length:\n",
    "        good_sentences.append(sentence)\n",
    "\n",
    "print(\"We will use {} sentences. \".format(len(good_sentences)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 65327\n",
      "Number of testing sentences: 9074\n",
      "Number of validation sentences: 16332\n"
     ]
    }
   ],
   "source": [
    "# good_sentences = good_sentences[:10000]\n",
    "train_data, test_data = train_test_split(good_sentences, test_size = 0.1, random_state = SEED)\n",
    "train_data, val_data = train_test_split(train_data, test_size = 0.2, random_state = SEED)\n",
    "\n",
    "print(\"Number of training sentences:\", len(train_data))\n",
    "print(\"Number of testing sentences:\", len(test_data))\n",
    "print(\"Number of validation sentences:\", len(val_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Yes, there's something of a sophistry about that,  Veslovsky agreed.\n",
      "I think you hailed me, Mademoiselle Julie.\n",
      "no, I could not endure William Coxe--a pert young lawyer.\n",
      "Weston, and had half a mind to take it up; but she struggled, and let it pass.\n",
      "Only it's no good your talking to her.\n"
     ]
    }
   ],
   "source": [
    "for i in range(105, 110):\n",
    "    sentence = ''\n",
    "    for j in train_data[i]:\n",
    "        sentence+=int_to_vocab[j]\n",
    "    # sentence = [int_to_vocab[j] for j in training_sorted[i]]\n",
    "    print(str(sentence))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "alphabet = [chr(i) for i in range(97, 123)]\n",
    "# print(alphabet)\n",
    "\n",
    "def noise_maker(sentence, threshold):\n",
    "    '''Relocate, remove, or add characters to create spelling mistakes'''\n",
    "\n",
    "    noisy_sentence = []\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        random = np.random.uniform()\n",
    "        if random < threshold:\n",
    "            noisy_sentence.append(sentence[i])\n",
    "        else:\n",
    "            random = np.random.uniform()\n",
    "            # 25% chance to swap locations\n",
    "            if random >= 0.75:\n",
    "                if i == (len(sentence) - 1):\n",
    "                    # Last character will not be typed\n",
    "                    continue\n",
    "                else:\n",
    "                    noisy_sentence.append(sentence[i+1])\n",
    "                    noisy_sentence.append(sentence[i])\n",
    "                    i += 1\n",
    "            # 25% chance to add an extra lower case letter\n",
    "            elif random > 0.5:\n",
    "                random_letter = np.random.choice(alphabet, 1)[0]\n",
    "                noisy_sentence.append(vocab_to_int[random_letter])\n",
    "                noisy_sentence.append(sentence[i])\n",
    "            # 25% chance of typos\n",
    "            elif random >= 0.25:\n",
    "                random_letter = np.random.choice(alphabet, 1)[0]\n",
    "                noisy_sentence.append(vocab_to_int[random_letter])\n",
    "            else:\n",
    "                pass\n",
    "        i += 1\n",
    "    return noisy_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and it's high time I did, and go to the devil with you.\n",
      "and it'sh igh time I didt, and o to thme devil with oy.u\n",
      "\n",
      "I will give him the good one, said he; I am sure he deserves it.\n",
      "I will gve him the goyodj one, yaid hI  a msurle hhe destrves it.\n",
      "\n",
      "We were longer this bout, and enjoyed it more.\n",
      "W weer longerj this bouto,a nd denjoyed it morae.\n",
      "\n",
      "' 'If that ain't mine.\n",
      "' 'If that ian'ht mine.\n",
      "\n",
      "No, father, stammered Villefort; at least, I hope not.\n",
      "No, fathue,r stammeree Villefort qgt leastm, I hope not.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = 0.9\n",
    "for i in range(6100, 6105):\n",
    "    sentence = ''\n",
    "    noizy_sentence = ''\n",
    "    for j in train_data[i]:\n",
    "        sentence+=int_to_vocab[j]\n",
    "    for j in noise_maker(train_data[i], threshold):\n",
    "        noizy_sentence+=int_to_vocab[j]\n",
    "\n",
    "    print(sentence)\n",
    "    print(noizy_sentence)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def pad_sentences(sentences):\n",
    "    \"\"\" Pad sentences with <PAD> \"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentences])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentences]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "class Generator(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.pad_sentences_noisy = np.array([])\n",
    "        self.pad_sentences = np.array([])\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        noisy_sentences = []\n",
    "        for sentence in self.data:\n",
    "            noisy_sent = [vocab_to_int['<SOS>']]\n",
    "            noisy_sent+=noise_maker(sentence, threshold)\n",
    "            noisy_sentences.append(noisy_sent)\n",
    "\n",
    "\n",
    "        eos_sentences = []\n",
    "        for sentence in self.data:\n",
    "            eos_sentence = [vocab_to_int['<SOS>']]\n",
    "            eos_sentence+=sentence\n",
    "            eos_sentence.append(vocab_to_int['<EOS>'])\n",
    "            eos_sentences.append(eos_sentence)\n",
    "\n",
    "        self.pad_sentences = np.array(pad_sentences(eos_sentences))\n",
    "        self.pad_sentences_noisy = np.array(pad_sentences(noisy_sentences))\n",
    "\n",
    "        # So source is like '<SOS>Xyz<PAD><PAD><PAD>'\n",
    "        # And target is like '<SOS>Xyz<EOS><PAD><PAD><PAD><PAD><PAD>'\n",
    "        # Lengths could be different\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.pad_sentences_noisy[index]), \\\n",
    "               torch.tensor(self.pad_sentences[index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src len, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src len, batch size, emb dim]\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        return hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):   # Is for one step => seq len == 1\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # n directions == 1\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, emb dim]\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # output = [seq len, batch size, hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hid dim]\n",
    "        # cell = [n layers * n directions, batch size, hid dim]\n",
    "        # prediction = [batch size, output dim]\n",
    "\n",
    "        return prediction, hidden, cell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        # src = [src len, batch size]\n",
    "        # trg = [trg len, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # first decoder input is <sos>\n",
    "        input = trg[0,:]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "\n",
    "    loss_hstr = []\n",
    "    acc_hstr = []\n",
    "\n",
    "    for i, (src, trg) in enumerate(tqdm(iterator)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src = src.clone().detach().to(device).transpose(0,1)\n",
    "        trg = trg.clone().detach().to(device).transpose(0,1)\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        _, idx = torch.max(output, -1)\n",
    "        correct = torch.sum(trg == idx)\n",
    "        acc = correct/(idx.shape[0]*idx.shape[1])\n",
    "        acc_hstr.append(acc.cpu())\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        loss_hstr.append(loss.item())\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    return loss_hstr, acc_hstr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_hstr = []\n",
    "    acc_hstr = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src = src.clone().detach().to(device).transpose(0,1)\n",
    "            trg = trg.clone().detach().to(device).transpose(0,1)\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            _, idx = torch.max(output, -1)\n",
    "            correct = torch.sum(trg == idx)\n",
    "            acc = correct/(idx.shape[0]*idx.shape[1])\n",
    "            acc_hstr.append(acc.cpu())\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            loss_hstr.append(loss.item())\n",
    "\n",
    "    return loss_hstr, acc_hstr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "threshold = 0.95\n",
    "\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(77, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(77, 256)\n    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n    (fc_out): Linear(in_features=512, out_features=77, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,435,341 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82c136d97c494af2bbfb9a31ad8f0e30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d7e8b92e6f8489089e4e17dab50c7e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 2m 47s\n",
      "\tTrain Loss: 1.605, Train acc: 0.265\n",
      "\t Val. Loss: 2.541, Val acc: 0.160\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d1d682cf19dd4df8b24b486d05faf2db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 2m 46s\n",
      "\tTrain Loss: 1.579, Train acc: 0.269\n",
      "\t Val. Loss: 2.505, Val acc: 0.163\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5525efc2056342fdaa0ed52755cb415a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 2m 50s\n",
      "\tTrain Loss: 1.547, Train acc: 0.273\n",
      "\t Val. Loss: 2.602, Val acc: 0.161\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eed011c6a89b4bd8acb801c8f8b3b0cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 2m 49s\n",
      "\tTrain Loss: 1.534, Train acc: 0.275\n",
      "\t Val. Loss: 2.603, Val acc: 0.159\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3657ce9958d8474f9c6a22d0ea9a7289"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 2m 47s\n",
      "\tTrain Loss: 1.526, Train acc: 0.276\n",
      "\t Val. Loss: 2.643, Val acc: 0.158\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14a05534e3444922af75be51ccc0a731"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 2m 47s\n",
      "\tTrain Loss: 1.506, Train acc: 0.278\n",
      "\t Val. Loss: 2.610, Val acc: 0.160\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02e539ccf223436f8fed23a4b0bf4c6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 2m 52s\n",
      "\tTrain Loss: 1.492, Train acc: 0.280\n",
      "\t Val. Loss: 2.452, Val acc: 0.169\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70f31b5ae8b2490dbefef9c449fdd3b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 2m 51s\n",
      "\tTrain Loss: 1.476, Train acc: 0.282\n",
      "\t Val. Loss: 2.583, Val acc: 0.164\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a014aaf389104ee4946bf95d4cc95156"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 2m 45s\n",
      "\tTrain Loss: 1.453, Train acc: 0.285\n",
      "\t Val. Loss: 2.594, Val acc: 0.165\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20b7a9cb105f4053b6972c40d357105c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 2m 47s\n",
      "\tTrain Loss: 1.441, Train acc: 0.287\n",
      "\t Val. Loss: 2.552, Val acc: 0.167\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1d4e51522fc4a5aaee1033183ba7848"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 2m 47s\n",
      "\tTrain Loss: 1.422, Train acc: 0.290\n",
      "\t Val. Loss: 2.542, Val acc: 0.169\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0911fd1c752d4609bad54d89508532ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 2m 45s\n",
      "\tTrain Loss: 1.407, Train acc: 0.291\n",
      "\t Val. Loss: 2.521, Val acc: 0.170\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2beafb000414bf6b0b93799b8e6bcaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 2m 43s\n",
      "\tTrain Loss: 1.398, Train acc: 0.293\n",
      "\t Val. Loss: 2.589, Val acc: 0.167\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b43dae83cb754a9c84cf067c304ff927"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 2m 45s\n",
      "\tTrain Loss: 1.389, Train acc: 0.294\n",
      "\t Val. Loss: 2.665, Val acc: 0.161\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe31e0e3965a42d986864def430bb594"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 2m 52s\n",
      "\tTrain Loss: 1.415, Train acc: 0.290\n",
      "\t Val. Loss: 2.579, Val acc: 0.166\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd1e35d4f9d341b0a5495659fccac67b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 2m 53s\n",
      "\tTrain Loss: 1.397, Train acc: 0.293\n",
      "\t Val. Loss: 2.584, Val acc: 0.166\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a871eb77925240cd9558de9f85c5b5fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 2m 47s\n",
      "\tTrain Loss: 1.388, Train acc: 0.294\n",
      "\t Val. Loss: 2.678, Val acc: 0.165\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc44f04e72aa42379b2da386ddf76226"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 2m 52s\n",
      "\tTrain Loss: 1.380, Train acc: 0.295\n",
      "\t Val. Loss: 2.528, Val acc: 0.170\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ffe8d54b5d34a65ab50391897878f3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 2m 45s\n",
      "\tTrain Loss: 1.359, Train acc: 0.298\n",
      "\t Val. Loss: 2.623, Val acc: 0.169\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1307 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b6540c05bfc4b23830f2d3a7b683d79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 2m 43s\n",
      "\tTrain Loss: 1.336, Train acc: 0.301\n",
      "\t Val. Loss: 2.634, Val acc: 0.171\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = vocab_to_int['<PAD>'])\n",
    "\n",
    "# train_data, test_data = train_test_split(good_sentences, test_size = 0.1, random_state = SEED)\n",
    "# train_data, val_data = train_test_split(train_data, test_size = 0.2, random_state = SEED)\n",
    "\n",
    "train_ds = Generator(train_data)\n",
    "train_ds.generate_dataset()\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=50)\n",
    "\n",
    "val_ds = Generator(val_data)\n",
    "val_ds.generate_dataset()\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=50)\n",
    "\n",
    "train_loss_history = []\n",
    "train_loss_avgs = []\n",
    "train_acc_history = []\n",
    "train_acc_avgs =[]\n",
    "\n",
    "val_loss_history = []\n",
    "val_loss_avgs = []\n",
    "val_acc_history = []\n",
    "val_acc_avgs =[]\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    train_loss_history+=train_loss\n",
    "    train_loss_avgs.append(np.mean(train_loss))\n",
    "    train_acc_history+=train_acc\n",
    "    train_acc_avgs.append(np.mean(train_acc))\n",
    "\n",
    "    val_loss_history+=val_loss\n",
    "    val_loss_avgs.append(np.mean(val_loss))\n",
    "    val_acc_history+=val_acc\n",
    "    val_acc_avgs.append(np.mean(val_acc))\n",
    "\n",
    "\n",
    "\n",
    "    if val_loss_avgs[-1] < best_valid_loss:\n",
    "        best_valid_loss = val_loss_avgs[-1]\n",
    "        torch.save(model.state_dict(), 'model_clip_1_newParam.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss_avgs[-1]:.3f}, Train acc: {train_acc_avgs[-1]:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss_avgs[-1]:.3f}, Val acc: {val_acc_avgs[-1]:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc_avgs)\n",
    "plt.plot(val_acc_avgs)\n",
    "plt.gca().legend(('train_acc_hstr', 'val_acc_hstr'))\n",
    "plt.show()\n",
    "# Overfitted.."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest Loss: 2.644, Test Acc: 0.168\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "test_ds = Generator(test_data)\n",
    "test_ds.generate_dataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=50)\n",
    "\n",
    "loss_hstr, acc_hstr = evaluate(model, test_loader, criterion)\n",
    "print(f'\\tTest Loss: {np.mean(loss_hstr):.3f}, Test Acc: {np.mean(acc_hstr):.3f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Need to train better.."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "    double_len = len(input)*2\n",
    "    tgt = [vocab_to_int['<SOS>']]\n",
    "    tgt += [vocab_to_int['<PAD>']] * double_len\n",
    "    tgt = torch.tensor(tgt).to(device)\n",
    "    tgt = torch.reshape(tgt, (-1,1))\n",
    "\n",
    "\n",
    "    inted_sent = [[vocab_to_int['<SOS>']]]\n",
    "    for letter in input:\n",
    "        inted_sent.append([vocab_to_int[letter]])\n",
    "\n",
    "    inted_sent = torch.tensor(np.array(inted_sent)).to(device)\n",
    "\n",
    "    sent = None\n",
    "    with torch.no_grad():\n",
    "            output = model(inted_sent, tgt, 0)\n",
    "            val, idx = torch.max(output, 2)\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            sent = idx.reshape((idx.shape[0]))\n",
    "\n",
    "    sentence = ''\n",
    "    for j in sent:\n",
    "        if int_to_vocab[j.item()] == '<EOS>':\n",
    "            return sentence\n",
    "        sentence+=int_to_vocab[j.item()]\n",
    "\n",
    "    return sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -very woll and you way  up.\n"
     ]
    }
   ],
   "source": [
    "sent = 'Let me show uyo something'\n",
    "print(predict(sent))\n",
    "\n",
    "# Meh..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "# Bad train and bad model. Maybe I need to spellCheck word by word.."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}